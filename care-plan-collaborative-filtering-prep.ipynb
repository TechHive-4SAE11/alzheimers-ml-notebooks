{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "158c28cb",
   "metadata": {},
   "source": [
    "# Care Plan Recommendation - Collaborative Filtering Data Preparation\n",
    "\n",
    "**Objective:** Prepare patient and care plan data for collaborative filtering algorithms to recommend personalized Alzheimer's care plans.\n",
    "\n",
    "**Data Sources:**\n",
    "- `alzheimers_disease_data.csv`: Patient health metrics\n",
    "- `care_plan_recommendations.csv`: Care plan assignments\n",
    "\n",
    "**Approach:**\n",
    "1. Load and explore care plan data\n",
    "2. Merge with patient data (using only Lasso-selected features from prediction model)\n",
    "3. Encode categorical variables\n",
    "4. Create user-item interaction matrix\n",
    "5. Analyze sparsity and distribution\n",
    "6. Save prepared datasets for collaborative filtering\n",
    "\n",
    "**Features Used:** Only the 16 features selected by Lasso regression in the prediction notebook for optimal model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2af8cd",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e733ab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning and preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9830dd",
   "metadata": {},
   "source": [
    "## 2. Load Care Plan Recommendations\n",
    "\n",
    "Loading the care plan assignment data to understand what care plans have been assigned to which patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dfe50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load care plan recommendations\n",
    "care_plans = pd.read_csv('data/care_plan_recommendations.csv')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CARE PLAN DATA OVERVIEW\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total care plans: {len(care_plans)}\")\n",
    "print(f\"Unique patients: {care_plans['PatientID'].nunique()}\")\n",
    "print(f\"Unique care plan IDs: {care_plans['CarePlanID'].nunique()}\")\n",
    "print(f\"\\nDataset shape: {care_plans.shape}\")\n",
    "print(f\"\\nColumns: {care_plans.columns.tolist()}\")\n",
    "print(f\"\\nRisk Level Distribution:\")\n",
    "print(care_plans['RiskLevel'].value_counts())\n",
    "print(f\"\\nPrimary Focus Distribution:\")\n",
    "print(care_plans['PrimaryFocus'].value_counts())\n",
    "\n",
    "care_plans.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f6f78e",
   "metadata": {},
   "source": [
    "## 3. Load Patient Data with Selected Features\n",
    "\n",
    "Loading patient health data and keeping **only the 16 features** selected by Lasso regression in the prediction model:\n",
    "\n",
    "**Selected Features:**\n",
    "1. Age\n",
    "2. EducationLevel\n",
    "3. Smoking\n",
    "4. SleepQuality\n",
    "5. CardiovascularDisease\n",
    "6. HeadInjury\n",
    "7. Hypertension\n",
    "8. CholesterolLDL\n",
    "9. CholesterolHDL\n",
    "10. CholesterolTriglycerides\n",
    "11. MMSE\n",
    "12. FunctionalAssessment\n",
    "13. MemoryComplaints\n",
    "14. BehavioralProblems\n",
    "15. ADL\n",
    "16. Disorientation\n",
    "\n",
    "*These features were identified as the most predictive in the Alzheimer's disease prediction model.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417cd66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full patient dataset\n",
    "df_full = pd.read_csv('data/alzheimers_disease_data.csv')\n",
    "\n",
    "# Define the 16 features selected by Lasso (from prediction notebook)\n",
    "selected_features = [\n",
    "    'Age', 'EducationLevel', 'Smoking', 'SleepQuality',\n",
    "    'CardiovascularDisease', 'HeadInjury', 'Hypertension',\n",
    "    'CholesterolLDL', 'CholesterolHDL', 'CholesterolTriglycerides',\n",
    "    'MMSE', 'FunctionalAssessment', 'MemoryComplaints',\n",
    "    'BehavioralProblems', 'ADL', 'Disorientation'\n",
    "]\n",
    "\n",
    "# Keep only PatientID, selected features, and Diagnosis\n",
    "patient_data = df_full[['PatientID'] + selected_features + ['Diagnosis']].copy()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PATIENT DATA WITH SELECTED FEATURES\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total patients: {len(patient_data)}\")\n",
    "print(f\"Features retained: {len(selected_features)}\")\n",
    "print(f\"Dataset shape: {patient_data.shape}\")\n",
    "print(f\"\\nFeatures: {selected_features}\")\n",
    "print(f\"\\nDiagnosis distribution:\")\n",
    "print(patient_data['Diagnosis'].value_counts())\n",
    "\n",
    "patient_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc95bb5",
   "metadata": {},
   "source": [
    "## 4. Merge Patient Features with Care Plans\n",
    "\n",
    "Combining patient health metrics with assigned care plans to create a unified dataset for collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge patient features with care plan data\n",
    "cf_data = care_plans.merge(patient_data, on='PatientID', how='inner')\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MERGED COLLABORATIVE FILTERING DATASET\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total records: {len(cf_data)}\")\n",
    "print(f\"Total columns: {len(cf_data.columns)}\")\n",
    "print(f\"Patients with care plans: {cf_data['PatientID'].nunique()}\")\n",
    "print(f\"Care plans assigned: {cf_data['CarePlanID'].nunique()}\")\n",
    "print(f\"\\nDataset shape: {cf_data.shape}\")\n",
    "print(f\"\\nMissing values: {cf_data.isnull().sum().sum()}\")\n",
    "\n",
    "print(f\"\\nColumns breakdown:\")\n",
    "print(f\"  - Care plan metadata: CarePlanID, RiskLevel, PrimaryFocus, CarePlanType, etc.\")\n",
    "print(f\"  - Patient features (Lasso-selected): {len(selected_features)} features\")\n",
    "print(f\"  - Target: Diagnosis\")\n",
    "\n",
    "cf_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acedeea",
   "metadata": {},
   "source": [
    "## 5. Encode Categorical Variables\n",
    "\n",
    "Preparing categorical care plan features for machine learning by encoding them numerically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f565b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for encoding\n",
    "cf_dataset = cf_data.copy()\n",
    "\n",
    "# Initialize label encoders\n",
    "le_risk = LabelEncoder()\n",
    "le_focus = LabelEncoder()\n",
    "le_type = LabelEncoder()\n",
    "\n",
    "# Encode categorical features\n",
    "cf_dataset['RiskLevel_Encoded'] = le_risk.fit_transform(cf_dataset['RiskLevel'])\n",
    "cf_dataset['PrimaryFocus_Encoded'] = le_focus.fit_transform(cf_dataset['PrimaryFocus'])\n",
    "cf_dataset['CarePlanType_Encoded'] = le_type.fit_transform(cf_dataset['CarePlanType'])\n",
    "\n",
    "# Create interaction column (all records represent patient-care plan assignments)\n",
    "cf_dataset['Interaction'] = 1\n",
    "\n",
    "# Store label mappings for interpretation\n",
    "label_mappings = {\n",
    "    'RiskLevel': dict(enumerate(le_risk.classes_)),\n",
    "    'PrimaryFocus': dict(enumerate(le_focus.classes_)),\n",
    "    'CarePlanType': dict(enumerate(le_type.classes_))\n",
    "}\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"CATEGORICAL ENCODING COMPLETE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nLabel Encodings:\")\n",
    "for feature, mapping in label_mappings.items():\n",
    "    print(f\"\\n{feature}:\")\n",
    "    for code, label in mapping.items():\n",
    "        print(f\"  {code} → {label}\")\n",
    "\n",
    "# Show sample of encoded data\n",
    "cf_dataset[['PatientID', 'CarePlanID', 'RiskLevel', 'RiskLevel_Encoded', \n",
    "            'PrimaryFocus', 'PrimaryFocus_Encoded', 'Interaction']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cb3d8b",
   "metadata": {},
   "source": [
    "## 6. Organize Collaborative Filtering Structure\n",
    "\n",
    "Defining the structure for collaborative filtering:\n",
    "- **User ID**: PatientID\n",
    "- **Item ID**: CarePlanID\n",
    "- **User Features**: 16 Lasso-selected patient health metrics\n",
    "- **Item Features**: Encoded care plan characteristics\n",
    "- **Interaction**: Binary indicator (1 = care plan assigned to patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755ba56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define collaborative filtering components\n",
    "user_id = 'PatientID'\n",
    "item_id = 'CarePlanID'\n",
    "interaction = 'Interaction'\n",
    "\n",
    "# User features (patient health metrics - Lasso selected)\n",
    "user_features = selected_features  # Already defined: 16 features\n",
    "\n",
    "# Item features (care plan characteristics - encoded)\n",
    "item_features = [\n",
    "    'RiskLevel_Encoded',\n",
    "    'PrimaryFocus_Encoded',\n",
    "    'CarePlanType_Encoded'\n",
    "]\n",
    "\n",
    "# Keep original labels for interpretation\n",
    "original_labels = ['RiskLevel', 'PrimaryFocus', 'CarePlanType', 'Diagnosis']\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"COLLABORATIVE FILTERING DATASET STRUCTURE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nUser ID: {user_id}\")\n",
    "print(f\"Item ID: {item_id}\")\n",
    "print(f\"Interaction: {interaction} (binary: 1 = care plan assigned)\")\n",
    "\n",
    "print(f\"\\nUser Features ({len(user_features)}):\")\n",
    "for i, feat in enumerate(user_features, 1):\n",
    "    print(f\"  {i:2d}. {feat}\")\n",
    "\n",
    "print(f\"\\nItem Features ({len(item_features)}):\")\n",
    "for i, feat in enumerate(item_features, 1):\n",
    "    print(f\"  {i}. {feat}\")\n",
    "\n",
    "print(f\"\\nOriginal Labels (for interpretation): {original_labels}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(f\"Dataset ready for collaborative filtering algorithms!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380608b0",
   "metadata": {},
   "source": [
    "## 7. Analyze Data Distribution and Sparsity\n",
    "\n",
    "Understanding the interaction matrix characteristics is crucial for selecting appropriate collaborative filtering algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a03ce46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate collaborative filtering metrics\n",
    "n_users = cf_dataset['PatientID'].nunique()\n",
    "n_items = cf_dataset['CarePlanID'].nunique()\n",
    "n_interactions = len(cf_dataset)\n",
    "\n",
    "# Calculate sparsity\n",
    "total_possible_interactions = n_users * n_items\n",
    "sparsity = 1 - (n_interactions / total_possible_interactions)\n",
    "density = 1 - sparsity\n",
    "\n",
    "# Analyze care plans per patient\n",
    "care_plans_per_patient = cf_dataset.groupby('PatientID').size()\n",
    "\n",
    "# Analyze patients per care plan\n",
    "patients_per_care_plan = cf_dataset.groupby('CarePlanID').size()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"COLLABORATIVE FILTERING METRICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nUser-Item Matrix Dimensions:\")\n",
    "print(f\"  Users (patients):        {n_users:,}\")\n",
    "print(f\"  Items (care plans):      {n_items:,}\")\n",
    "print(f\"  Total interactions:      {n_interactions:,}\")\n",
    "\n",
    "print(f\"\\nSparsity Analysis:\")\n",
    "print(f\"  Possible interactions:   {total_possible_interactions:,}\")\n",
    "print(f\"  Actual interactions:     {n_interactions:,}\")\n",
    "print(f\"  Sparsity:                {sparsity:.4%}\")\n",
    "print(f\"  Density:                 {density:.4%}\")\n",
    "\n",
    "print(f\"\\nInteraction Distribution:\")\n",
    "print(f\"  Care plans per patient:\")\n",
    "print(f\"    Mean:   {care_plans_per_patient.mean():.2f}\")\n",
    "print(f\"    Median: {care_plans_per_patient.median():.0f}\")\n",
    "print(f\"    Min:    {care_plans_per_patient.min()}\")\n",
    "print(f\"    Max:    {care_plans_per_patient.max()}\")\n",
    "\n",
    "print(f\"\\n  Patients per care plan:\")\n",
    "print(f\"    Mean:   {patients_per_care_plan.mean():.2f}\")\n",
    "print(f\"    Median: {patients_per_care_plan.median():.0f}\")\n",
    "print(f\"    Min:    {patients_per_care_plan.min()}\")\n",
    "print(f\"    Max:    {patients_per_care_plan.max()}\")\n",
    "\n",
    "print(f\"\\nRisk Level Distribution:\")\n",
    "for level, count in cf_dataset['RiskLevel'].value_counts().items():\n",
    "    print(f\"  {level:8s}: {count:4d} ({count/len(cf_dataset)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nPrimary Focus Distribution:\")\n",
    "for focus, count in cf_dataset['PrimaryFocus'].value_counts().items():\n",
    "    print(f\"  {focus:20s}: {count:4d} ({count/len(cf_dataset)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62860d8",
   "metadata": {},
   "source": [
    "## 8. Visualize Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4adfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. Risk Level Distribution\n",
    "cf_dataset['RiskLevel'].value_counts().plot(kind='bar', ax=axes[0, 0], color='coral')\n",
    "axes[0, 0].set_title('Risk Level Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Risk Level')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# 2. Primary Focus Distribution\n",
    "cf_dataset['PrimaryFocus'].value_counts().plot(kind='bar', ax=axes[0, 1], color='skyblue')\n",
    "axes[0, 1].set_title('Primary Focus Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Primary Focus')\n",
    "axes[0, 1].set_ylabel('Count')\n",
    "axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 3. Care Plans per Patient\n",
    "axes[1, 0].hist(care_plans_per_patient, bins=20, color='lightgreen', edgecolor='black')\n",
    "axes[1, 0].set_title('Care Plans per Patient', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Number of Care Plans')\n",
    "axes[1, 0].set_ylabel('Number of Patients')\n",
    "\n",
    "# 4. Patients per Care Plan\n",
    "axes[1, 1].hist(patients_per_care_plan, bins=20, color='plum', edgecolor='black')\n",
    "axes[1, 1].set_title('Patients per Care Plan', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Number of Patients')\n",
    "axes[1, 1].set_ylabel('Number of Care Plans')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ Visualizations generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bc0e2b",
   "metadata": {},
   "source": [
    "## 9. Save Prepared Datasets\n",
    "\n",
    "Saving two versions of the dataset:\n",
    "1. **Full dataset**: All columns including original labels and encoded features\n",
    "2. **Compact dataset**: Essential columns only for CF algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a11127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save full dataset with all columns\n",
    "cf_dataset.to_csv('data/cf_care_plan_data.csv', index=False)\n",
    "\n",
    "# Create compact version with only essential columns for CF\n",
    "essential_columns = (\n",
    "    [user_id, item_id, interaction] +\n",
    "    user_features +\n",
    "    item_features +\n",
    "    original_labels\n",
    ")\n",
    "\n",
    "cf_compact = cf_dataset[essential_columns].copy()\n",
    "cf_compact.to_csv('data/cf_care_plan_compact.csv', index=False)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DATASETS SAVED SUCCESSFULLY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\n1. Full Dataset:\")\n",
    "print(f\"   File:    data/cf_care_plan_data.csv\")\n",
    "print(f\"   Shape:   {cf_dataset.shape}\")\n",
    "print(f\"   Columns: {len(cf_dataset.columns)}\")\n",
    "print(f\"   Purpose: Complete data with all original and encoded features\")\n",
    "\n",
    "print(f\"\\n2. Compact Dataset:\")\n",
    "print(f\"   File:    data/cf_care_plan_compact.csv\")\n",
    "print(f\"   Shape:   {cf_compact.shape}\")\n",
    "print(f\"   Columns: {len(cf_compact.columns)}\")\n",
    "print(f\"   Purpose: Essential features only for CF algorithms\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "print(\"COLLABORATIVE FILTERING DATA PREPARATION COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nDataset Summary:\")\n",
    "print(f\"  • {n_users:,} unique patients (users)\")\n",
    "print(f\"  • {n_items:,} unique care plans (items)\")\n",
    "print(f\"  • {n_interactions:,} patient-care plan interactions\")\n",
    "print(f\"  • {len(user_features)} patient health features (Lasso-selected)\")\n",
    "print(f\"  • {len(item_features)} care plan features (encoded)\")\n",
    "print(f\"  • Sparsity: {sparsity:.2%}\")\n",
    "\n",
    "print(f\"\\nRecommended Collaborative Filtering Algorithms:\")\n",
    "print(f\"  1. Matrix Factorization (SVD, NMF)\")\n",
    "print(f\"  2. Neural Collaborative Filtering (NCF)\")\n",
    "print(f\"  3. LightFM (hybrid recommender)\")\n",
    "print(f\"  4. Surprise library (SVD, KNN)\")\n",
    "print(f\"  5. Deep Learning (TensorFlow Recommenders)\")\n",
    "\n",
    "print(f\"\\n✓ Ready for model training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6d650f",
   "metadata": {},
   "source": [
    "## 10. Preview Prepared Data\n",
    "\n",
    "Final preview of the compact dataset structure ready for collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5168c48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of compact dataset\n",
    "print(\"=\" * 70)\n",
    "print(\"COMPACT DATASET PREVIEW (First 10 Rows)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nColumns: {cf_compact.columns.tolist()}\")\n",
    "print(f\"\\nSample data:\")\n",
    "\n",
    "# Show first 10 rows with key columns\n",
    "display_cols = [user_id, item_id, interaction] + user_features[:5] + item_features + ['RiskLevel', 'PrimaryFocus']\n",
    "cf_compact[display_cols].head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
